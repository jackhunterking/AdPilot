/**
 * Feature: AI Chat Streaming Route
 * Purpose: Handle chat streaming with AI Gateway and optimized message persistence
 * References:
 *  - AI SDK Core: https://ai-sdk.dev/docs/ai-sdk-core/streaming
 *  - AI Gateway: https://vercel.com/docs/ai-gateway
 *  - Conversation History: https://ai-sdk.dev/docs/ai-sdk-core/conversation-history
 */

// UUID validation helper to distinguish database IDs from AI SDK-generated IDs
function isValidUUID(str: string): boolean {
  const uuidRegex = /^[0-9a-f]{8}-[0-9a-f]{4}-[0-9a-f]{4}-[0-9a-f]{4}-[0-9a-f]{12}$/i;
  return uuidRegex.test(str);
}

import { 
  convertToModelMessages, 
  streamText, 
  UIMessage, 
  createIdGenerator, 
  safeValidateUIMessages,
  NoSuchToolError,
  InvalidToolInputError,
  ToolCallRepairError,
  stepCountIs,
  Tool,
} from 'ai';
import { sanitizeMessages, isSanitizerEnabled } from '@/lib/ai/schema';
// Import granular tool categories
import * as creativeTools from '@/lib/ai/tools/creative';
import * as copyTools from '@/lib/ai/tools/copy';
import * as targetingTools from '@/lib/ai/tools/targeting';
import * as campaignTools from '@/lib/ai/tools/campaign';
import * as goalTools from '@/lib/ai/tools/goal';

// Backward compatibility imports (temporary during migration)
import { generateImageTool, editImageTool, regenerateImageTool, editAdCopyTool, locationTargetingTool, createAdTool, setupGoalTool } from '@/lib/ai/tools';
import { getCachedMetrics } from '@/lib/meta/insights';
import { getModel } from '@/lib/ai/gateway-provider';
import { messageStore } from '@/lib/services/message-store';
import { conversationManager } from '@/lib/services/conversation-manager';
import { autoSummarizeIfNeeded } from '@/lib/ai/summarization';
import { createServerClient } from '@/lib/supabase/server';
import { createCreativePlan } from '@/lib/ai/system/creative-guardrails';

// Allow streaming responses up to 30 seconds
export const maxDuration = 30;

/**
 * Get goal-specific context description for system prompt
 * Provides detailed guidance for each campaign goal type
 */
function getGoalContextDescription(goalType: string): string {
  switch(goalType) {
    case 'calls':
      return `This campaign is optimized for generating PHONE CALLS.

**Visual & Creative Guidelines:**
- Include trust signals (professional imagery, credentials, testimonials)
- Emphasize personal connection and accessibility
- Show real people, faces, and direct communication
- Use warm, inviting tones and approachable imagery
- Subtle phone/contact imagery may be included but focus on human connection

**Copy & Messaging:**
- CTAs should encourage immediate calling: "Call Now", "Speak to an Expert", "Get Your Free Consultation"
- Emphasize urgency and availability: "Available 24/7", "Talk to us today"
- Highlight the value of direct conversation
- Include phone numbers prominently when relevant`;
    
    case 'leads':
      return `This campaign is optimized for LEAD GENERATION through form submissions.

**Visual & Creative Guidelines:**
- Include value exchange imagery (forms, checklists, downloads, assessments)
- Show transformation and results from information sharing
- Emphasize trust and data security with professional visuals
- Use imagery suggesting consultation, assessment, or personalized service
- Clean, organized layouts that suggest form completion

**Copy & Messaging:**
- CTAs for form submission: "Sign Up", "Get Your Free Quote", "Request Information", "Download Now"
- Emphasize value exchange: "Free", "Exclusive", "Personalized"
- Reduce friction: "Quick", "Easy", "Just 2 minutes"
- Highlight what they'll receive for their information`;
    
    case 'website-visits':
      return `This campaign is optimized for driving WEBSITE TRAFFIC and browsing.

**Visual & Creative Guidelines:**
- Show browsing and discovery actions (screens, devices, online shopping)
- Include product catalogs, website interfaces, or digital storefronts
- Emphasize exploration and online presence
- Use imagery suggesting clicking, scrolling, browsing
- Show variety and selection available online

**Copy & Messaging:**
- CTAs for website visits: "Shop Now", "Explore More", "View Collection", "Browse Catalog", "Learn More"
- Emphasize discovery: "Discover", "Explore", "Browse"
- Highlight online benefits: "Shop from home", "100+ options online"
- Create curiosity to drive clicks`;
    
    default:
      return 'No specific goal has been set for this campaign yet. Ask the user about their campaign objectives if needed.';
  }
}

function formatNumber(value: number | null | undefined): string {
  if (value == null || Number.isNaN(value)) return '0'
  return new Intl.NumberFormat('en-US', { maximumFractionDigits: 1 }).format(value)
}

export async function POST(req: Request) {
  const { message, id, model } = await req.json();
  
  // DEBUG: Log incoming message structure (AI SDK v5 pattern - metadata field)
  console.log(`[API] ========== INCOMING MESSAGE ==========`);
  console.log(`[API] message.id:`, message?.id);
  console.log(`[API] message.role:`, message?.role);
  console.log(`[API] message.metadata:`, JSON.stringify(message?.metadata || null));
  console.log(`[API] message has editingReference:`, !!(message?.metadata?.editingReference));
  if (message?.metadata?.editingReference) {
    console.log(`[API] editingReference content:`, message.metadata.editingReference);
  }

  const activeTab = message?.metadata?.activeTab === 'results' ? 'results' : 'setup';
  console.log(`[API] activeTab context:`, activeTab);
  
  // Authenticate user
  const supabase = await createServerClient();
  // Prefer cookie-based session; fallback to Authorization: Bearer <jwt>
  const { data: { user: cookieUser }, error: authError } = await supabase.auth.getUser();
  
  // Try bearer token if no cookie session
  let user = cookieUser;
  if (!user) {
    const authHeader = req.headers.get('authorization') || '';
    const lower = authHeader.toLowerCase();
    const bearer = lower.startsWith('bearer ') ? authHeader.slice(7).trim() : undefined;
    if (bearer) {
      try {
        const byToken = await supabase.auth.getUser(bearer);
        user = byToken.data.user ?? null;
      } catch {
        // ignore; will fall through to 401 if still no user
      }
    }
  }
  
  if ((authError && !user) || !user) {
    return new Response('Unauthorized', { status: 401 });
  }
  
  const tools = {
    // NEW GRANULAR TOOLS (Preferred - Microservice Pattern)
    // Creative operations
    generateVariations: creativeTools.generateVariationsTool,
    selectVariation: creativeTools.selectVariationTool,
    editVariation: creativeTools.editVariationTool,
    regenerateVariation: creativeTools.regenerateVariationTool,
    deleteVariation: creativeTools.deleteVariationTool,
    
    // Copy operations  
    generateCopyVariations: copyTools.generateCopyVariationsTool,
    selectCopyVariation: copyTools.selectCopyVariationTool,
    editCopy: copyTools.editCopyTool,
    refineHeadline: copyTools.refineHeadlineTool,
    refinePrimaryText: copyTools.refinePrimaryTextTool,
    refineDescription: copyTools.refineDescriptionTool,
    
    // Targeting operations
    addLocations: targetingTools.addLocationsTool,
    removeLocation: targetingTools.removeLocationTool,
    clearLocations: targetingTools.clearLocationsTool,
    
    // Campaign operations
    createAd: campaignTools.createAdTool,
    renameAd: campaignTools.renameAdTool,
    duplicateAd: campaignTools.duplicateAdTool,
    deleteAd: campaignTools.deleteAdTool,
    
    // Goal operations
    setupGoal: goalTools.setupGoalTool,
    
    // DEPRECATED: Old monolithic tools (backward compatibility)
    // These will be removed after migration is complete
    generateImage: generateImageTool, // DEPRECATED: use generateVariations
    editImage: editImageTool, // DEPRECATED: use editVariation
    regenerateImage: regenerateImageTool, // DEPRECATED: use regenerateVariation
    locationTargeting: locationTargetingTool, // DEPRECATED: use addLocations
    editAdCopy: editAdCopyTool, // DEPRECATED: use editCopy
  };

  // Get or create conversation
  // The 'id' can be either a campaign ID, conversation ID, or AI SDK-generated ID
  let conversationId = id;
  let conversation = null;
  
  console.log(`[API] ========== CONVERSATION ID RESOLUTION ==========`);
  console.log(`[API] Received id:`, id);
  console.log(`[API] Is valid UUID:`, id ? isValidUUID(id) : 'N/A (no id)');
  
  if (id) {
    // Check if it's a valid UUID (database ID)
    if (isValidUUID(id)) {
      console.log(`[API] ‚úÖ Valid UUID detected, attempting database lookup`);
      
      // Try to get conversation by ID first
      conversation = await conversationManager.getConversation(id);
      
      // If not found, check if it's a campaign ID
      if (!conversation) {
        console.log(`[API] Not found as conversation ID, trying as campaign ID`);
        conversation = await conversationManager.getOrCreateForCampaign(user.id, id);
        conversationId = conversation.id;
        console.log(`[API] ‚úÖ Created/found conversation ${conversationId} for campaign ${id}`);
      } else {
        console.log(`[API] ‚úÖ Using existing conversation ${conversationId}`);
      }
    } else {
      // Not a UUID - it's an AI SDK-generated ID (e.g., conv_1762821485606_h0uawxrjf)
      console.log(`[API] ‚ö†Ô∏è  Non-UUID ID detected (AI SDK generated): ${id}`);
      console.log(`[API] Extracting campaignId from message metadata...`);
      
      // Extract campaignId from message metadata
      const campaignIdFromMetadata = message?.metadata?.campaignId as string | undefined;
      console.log(`[API] Campaign ID from metadata:`, campaignIdFromMetadata);
      
      if (campaignIdFromMetadata && isValidUUID(campaignIdFromMetadata)) {
        console.log(`[API] ‚úÖ Valid campaign ID found in metadata, creating conversation`);
        conversation = await conversationManager.getOrCreateForCampaign(
          user.id,
          campaignIdFromMetadata
        );
        conversationId = conversation.id;
        console.log(`[API] ‚úÖ Created/found conversation ${conversationId} for campaign ${campaignIdFromMetadata}`);
      } else {
        console.error(`[API] ‚ùå No valid campaign ID found. AI SDK generated ID but no campaignId in metadata.`);
        console.error(`[API] Message metadata:`, JSON.stringify(message?.metadata || {}, null, 2));
        return new Response(
          JSON.stringify({ 
            error: 'Campaign ID required for new conversations',
            details: 'Please provide a valid campaign ID in message metadata'
          }),
          { 
            status: 400,
            headers: { 'Content-Type': 'application/json' }
          }
        );
      }
    }
  } else {
    console.log(`[API] ‚ö†Ô∏è  No id provided, conversation will be created without campaign link`);
  }
  
  // Extract goal from conversation metadata (source of truth) or message metadata (fallback)
  const conversationGoal = (conversation?.metadata && typeof conversation.metadata === 'object' && 'current_goal' in conversation.metadata) 
    ? (conversation.metadata.current_goal as string) 
    : null;
  const messageGoal = message?.metadata?.goalType || null;
  const effectiveGoal = conversationGoal || messageGoal || null;
  
  // Extract current step from message metadata for step-aware behavior
  const currentStep = message?.metadata?.currentStep || null;
  
  console.log(`[API] Goal context:`, {
    conversationGoal,
    messageGoal,
    effectiveGoal,
  });
  
  console.log(`[API] Current step:`, currentStep);

  let resultsContext = '';
  if (activeTab === 'results' && conversation?.campaign_id) {
    try {
      const metrics = await getCachedMetrics(conversation.campaign_id, '7d')
      if (metrics) {
        resultsContext = `\n[RESULTS SNAPSHOT]\n- People reached: ${formatNumber(metrics.reach)}\n- Total ${effectiveGoal === 'leads' ? 'leads' : effectiveGoal === 'calls' ? 'calls' : 'results'}: ${formatNumber(metrics.results)}\n- Amount spent: $${formatNumber(metrics.spend)}\n- Cost per result: ${metrics.cost_per_result != null ? '$' + formatNumber(metrics.cost_per_result) : 'not enough data yet'}`
      } else {
        resultsContext = `\n[RESULTS SNAPSHOT]\nNo cached metrics yet. Invite the user to refresh the Results tab.`
      }
    } catch (error) {
      console.warn('[API] Failed to load metrics snapshot for chat context:', error)
    }
  }

  const tabInstructions = activeTab === 'results'
    ? `\n[RESULTS MODE]\nThe user is viewing the Results tab. Focus on:\n- Explaining metrics in plain language\n- Suggesting optimisations based on the numbers above\n- Offering to adjust budget, schedule, or targeting when helpful\nDo NOT ask setup questions unless the user switches back to Setup.`
    : '';

  // Load creative guardrails and offer context
  let planContext = '';
  let offerAskContext = '';
  let planId: string | null = null;
  if (conversation?.campaign_id && effectiveGoal) {
    // Creative plans table removed - using simplified approach
    // Try to read offer from conversation metadata
    let offerText: string | null = null;
    try {
      const conversationMeta = (conversation.metadata as { offerText?: string } | null) || null;
      offerText = conversationMeta?.offerText || null;
    } catch (e) {
      console.warn('[API] Could not read conversation metadata:', e);
    }

    // Quick extraction from latest user message if needed
    if (!offerText && message?.role === 'user' && typeof (message as { content?: unknown }).content === 'string') {
      const text = (message as unknown as { content: string }).content;
      if (/free|%\s*off|discount|quote|consult|download|trial/i.test(text)) {
        offerText = text;
      }
    }
    
    if (!offerText) {
      // Stricter ask-one-offer-question branch
      offerAskContext = `\n[OFFER REQUIRED - INITIAL SETUP]\nAsk ONE concise question to capture the user's concrete offer/value (e.g., "Free quote", "% off", "Consultation", "Download").\n\n**When Asking:**\n- Ask ONLY this one question, no extra text.\n- Do NOT call any tools yet.\n- Do NOT ask about location, audience, or targeting.\n- Wait for user's response.\n\n**CRITICAL - After User Answers:**\n- Provide brief acknowledgment (1 sentence): "Perfect! Creating your ${effectiveGoal || 'campaign'} ads with that offer..."\n- IMMEDIATELY call generateImage tool ONLY with the offer incorporated\n- Use appropriate format based on offer type:\n  * Discounts/percentages (e.g., "20% off") ‚Üí Include text overlay in prompt\n  * "Free" offers ‚Üí Text overlay or notes-style aesthetic\n  * Product/service names ‚Üí Clean professional imagery\n- Do NOT ask any follow-up questions\n- Do NOT call setupGoal tool (goal is already set)\n- Do NOT call locationTargeting tool (location comes later in build phase)\n- Do NOT call any other tools besides generateImage\n- Generate creative immediately with generateImage ONLY`;
    } else {
      // Store offer in conversation metadata for future reference
      try {
        await supabase
          .from('conversations')
          .update({
            metadata: {
              ...(conversation.metadata as Record<string, unknown> || {}),
              offerText,
            }
          })
          .eq('id', conversation.id);
        
        planContext = `\n[CREATIVE PLAN ACTIVE]\nFollow plan coverage and constraints. Generate square and vertical with vertical reusing the same base square image via extended canvas (blur/gradient/solid). Keep edges clean and reflow overlays within edge-safe areas; never draw frames or labels. Respect copy limits: primary ‚â§125, headline ‚â§40, description ‚â§30.`;
      } catch (e) {
        console.warn('[API] Failed to update conversation metadata:', e);
      }
    }
  }

  // Load and validate messages from database (AI SDK docs pattern)
  let validatedMessages: UIMessage[];
  
  // Load previous messages + append new one
  if (message && conversationId) {
    console.log(`[API] Loading messages for conversation ${conversationId}`);
    
    // Use message store service (optimized query with seq-based ordering)
    const previousMessages = await messageStore.loadMessages(conversationId, {
      limit: 80, // Load last 80 messages (configurable window)
    });
    
    const messages = [...previousMessages, message];
    
    console.log(`[API] Total messages: ${messages.length} (${previousMessages.length} loaded + 1 new)`);
    
    // Safe validate loaded messages against tools (AI SDK docs)
    // Returns validation result without throwing, allowing graceful error handling
      let validationResult:
        | { success: true; data: UIMessage[] }
        | { success: false; error: unknown };
    try {
      const toValidate = isSanitizerEnabled() ? sanitizeMessages(messages) : messages;
      validationResult = await safeValidateUIMessages({
        messages: toValidate,
          tools: tools as unknown as Record<string, Tool<unknown, unknown>>,
      });
    } catch (err) {
      console.error('[API] ‚ùå safeValidateUIMessages threw:', err);
        validationResult = { success: false, error: err };
    }
    
    if (validationResult.success) {
      validatedMessages = validationResult.data;
      console.log(`[API] ‚úÖ Validated ${validatedMessages.length} messages`);
    } else {
      // Validation failed - log errors and use only the new message
      console.error('[API] ‚ùå Message validation failed:', validationResult.error);
      console.log('[API] Starting with fresh conversation (new message only)');
      validatedMessages = [message];
    }
  } else {
    validatedMessages = [];
  }

  // Check if model supports specific features
  const isGeminiImageModel = model === 'google/gemini-2.5-flash-image-preview';
  // Only o1 models support reasoning parameters
  const isOpenAIReasoningModel = typeof model === 'string' && (model.includes('o1-preview') || model.includes('o1-mini'));

  // Extract reference context from message metadata (AI SDK v5 native pattern)
  let referenceContext = '';
  let isEditMode = false;
  let isLocationSetupMode = false;
  let locationInput = '';
  
  if (message?.metadata) {
    const metadata = message.metadata as Record<string, unknown>;
    isEditMode = Boolean(metadata.editMode);
    isLocationSetupMode = Boolean(metadata.locationSetupMode);
    locationInput = typeof metadata.locationInput === 'string' ? metadata.locationInput : '';
    
    // Handle ad editing reference
    if (metadata.editingReference) {
      const rawRef = metadata.editingReference as Record<string, unknown>;
      // Normalize variation index (accept legacy variationNumber)
      const variationIndex = typeof (rawRef as { variationIndex?: unknown }).variationIndex === 'number'
        ? (rawRef as { variationIndex: number }).variationIndex
        : (typeof (rawRef as { variationNumber?: unknown }).variationNumber === 'number' 
            ? Math.max(0, (rawRef as { variationNumber: number }).variationNumber - 1) 
            : undefined);
      const ref = { ...rawRef, variationIndex } as Record<string, unknown>;
      referenceContext += `\n\n[USER IS EDITING: ${ref.variationTitle}`;
      if (ref.format) referenceContext += ` (${ref.format} format)`;
      referenceContext += `]\n`;
      
      if (ref.imageUrl) {
        referenceContext += `Image URL: ${ref.imageUrl}\n`;
      }
      
      if (ref.variationIndex !== undefined) {
        referenceContext += `Variation Index: ${ref.variationIndex}\n`;
      }
      
      if (ref.content && typeof ref.content === 'object') {
        const content = ref.content as { primaryText?: string; headline?: string; description?: string };
        referenceContext += `Current content:\n`;
        if (content.primaryText) referenceContext += `- Primary Text: "${content.primaryText}"\n`;
        if (content.headline) referenceContext += `- Headline: "${content.headline}"\n`;
        if (content.description) referenceContext += `- Description: "${content.description}"\n`;
      }

      // Decide which toolset to expose based on fields
      const isCopyEdit = Array.isArray((ref as { metadata?: { fields?: string[] } }).metadata?.fields)
        ? ((ref as { metadata?: { fields?: string[] } }).metadata!.fields!).some((f: string) => ['primaryText','headline','description'].includes(f))
        : Boolean(ref.content);

      if (isCopyEdit) {
        referenceContext += `\n**You MUST call this tool:**\n`;
        referenceContext += `- editAdCopy: Rewrite primaryText/headline/description based on the user's instruction.\n`;
        referenceContext += `\n**Required parameters:**\n`;
        referenceContext += `- variationIndex: ${ref.variationIndex}\n`;
        referenceContext += `- current: {primaryText, headline, description} from context above\n`;
        referenceContext += `- prompt: The user's instruction\n`;
        referenceContext += `\nAfter calling editAdCopy, do not output any other text.\n`;
      } else {
        referenceContext += `\n**You MUST use one of these tools:**\n`;
        referenceContext += `- editImage: If user wants to MODIFY this image (change colors, adjust brightness, remove/add elements)\n`;
        referenceContext += `- regenerateImage: If user wants a COMPLETELY NEW VERSION of this variation\n`;
        referenceContext += `\n**Required parameters:**\n`;
        referenceContext += `- imageUrl: ${ref.imageUrl}\n`;
        referenceContext += `- variationIndex: ${ref.variationIndex}\n`;
        referenceContext += `- campaignId: (from context)\n`;
        referenceContext += `\nThe user's message below describes the changes they want to make.\n`;
      }

      // Wrap edit tools to enforce the locked reference during this request
      const locked = { 
        variationIndex: ref.variationIndex as number | undefined, 
        imageUrl: ref.imageUrl as string | undefined, 
        sessionId: (ref as { editSession?: { sessionId?: string } })?.editSession?.sessionId 
      };
      if (typeof locked.variationIndex === 'number') {
        // Override execute while preserving types via unknown casts at the edge
        (tools as unknown as Record<string, unknown>).editImage = {
          ...editImageTool,
          execute: async (input: unknown, ctx: unknown) => {
            const provided = input as { variationIndex?: number; imageUrl?: string };
            const enforced = { ...provided, variationIndex: locked.variationIndex, imageUrl: locked.imageUrl };
            console.log('[LOCK] editImage enforced index/url:', { locked, provided });
            const exec = (editImageTool as unknown as { execute: (i: unknown, c: unknown) => Promise<unknown> }).execute;
            const result = await exec(enforced, ctx);
            return { ...(result as object), variationIndex: locked.variationIndex, sessionId: locked.sessionId };
          }
        } as unknown;
        (tools as unknown as Record<string, unknown>).regenerateImage = {
          ...regenerateImageTool,
          execute: async (input: unknown, ctx: unknown) => {
            const provided = input as { variationIndex?: number };
            const enforced = { ...provided, variationIndex: locked.variationIndex };
            console.log('[LOCK] regenerateImage enforced index:', { lockedIndex: locked.variationIndex, provided: provided.variationIndex });
            const exec = (regenerateImageTool as unknown as { execute: (i: unknown, c: unknown) => Promise<unknown> }).execute;
            const result = await exec(enforced, ctx);
            return { ...(result as object), variationIndex: locked.variationIndex, sessionId: locked.sessionId };
          }
        } as unknown;
        (tools as unknown as Record<string, unknown>).editAdCopy = {
          ...editAdCopyTool,
          execute: async (input: unknown, ctx: unknown) => {
            const provided = input as { variationIndex?: number; current?: { primaryText?: string; headline?: string; description?: string } };
            const enforced = { ...provided, variationIndex: locked.variationIndex };
            const exec = (editAdCopyTool as unknown as { execute: (i: unknown, c: unknown) => Promise<unknown> }).execute;
            const result = await exec(enforced, ctx);
            return { ...(result as object), variationIndex: locked.variationIndex, sessionId: locked.sessionId };
          }
        } as unknown;
      }
    }
  }

  // Use AI Gateway for model routing and observability
  // AI SDK v5 automatically uses AI Gateway when AI_GATEWAY_API_KEY is set
  const modelId = getModel(model || 'openai/gpt-4o');
  
  const result = streamText({
    model: modelId, // Pass model string - AI SDK auto-routes through gateway
    messages: convertToModelMessages(validatedMessages),
    
    // Enable multi-step agentic behavior (AI SDK best practice)
    stopWhen: stepCountIs(5), // Allow up to 5 steps for tool execution
    
    // Track each step for debugging (AI SDK best practice)
    onStepFinish: ({ toolCalls, toolResults }) => {
      // Validate tool calls don't mix creative and build tools
      const creativeTools = ['generateImage', 'editImage', 'regenerateImage', 'editAdCopy'];
      const buildTools = ['locationTargeting', 'setupGoal'];
      
      const hasCreativeTool = toolCalls.some(tc => creativeTools.includes(tc.toolName));
      const hasBuildTool = toolCalls.some(tc => buildTools.includes(tc.toolName));
      
      // Log validation error if mixed tools detected
      if (hasCreativeTool && hasBuildTool) {
        console.error('[VALIDATION] ‚ùå INVALID: Mixed creative and build tools in same step!');
        console.error('[VALIDATION] Current step:', currentStep || 'ads');
        console.error('[VALIDATION] Tool calls:', toolCalls.map(tc => tc.toolName));
        console.error('[VALIDATION] This should NEVER happen. Check system prompt enforcement.');
      }
      
      // Log for debugging
      console.log(`[STEP] Finished step with ${toolCalls.length} tool calls, ${toolResults.length} results`);
      if (toolCalls.length > 0) {
        console.log(`[STEP] Tool calls:`, toolCalls.map(tc => ({ 
          name: tc.toolName, 
          hasExecute: tc.toolName === 'generateImage' ? 'NO (client-side)' : 'varies' 
        })));
      }
      if (toolResults.length > 0) {
        console.log(`[STEP] Tool results:`, toolResults.map(tr => ({ 
          tool: tr.toolName, 
          hasResult: Boolean((tr as unknown as { result?: unknown }).result) 
        })));
      }
    },
    
    system: `${isLocationSetupMode ? `
# üéØ CRITICAL: LOCATION SETUP MODE ACTIVE üéØ

The user just provided location name(s) in response to your question: "${locationInput}"

YOU MUST CALL THE addLocations TOOL NOW with EXACTLY what the user typed. No exceptions.

**CRITICAL RULES:**
1. Process ONLY the location the user provided: "${locationInput}"
2. DO NOT suggest multiple locations
3. DO NOT add variations or alternatives
4. DO NOT call any other tools
5. DO NOT ask for confirmation
6. Call addLocations with ONE location only

**Mode Detection:**
- If user said "exclude" ‚Üí mode: "exclude"
- Otherwise ‚Üí mode: "include"

**Type Detection:**
- If radius/miles mentioned ‚Üí type: "radius"
- If state/province name ‚Üí type: "region"
- If country name ‚Üí type: "country"
- Otherwise ‚Üí type: "city" (default)

**CORRECT FORMAT (Process ONLY user's input):**
addLocations({
  locations: [
    {
      name: "${locationInput}",
      type: "city",
      mode: "include"
    }
  ],
  explanation: "Added ${locationInput}"
})

DO NOT ADD OTHER LOCATIONS. DO NOT SUGGEST ALTERNATIVES. PROCESS ONLY WHAT USER TYPED.

CALL THE TOOL NOW. DO NOT OUTPUT ANY OTHER TEXT.

` : isEditMode ? `
# üö® CRITICAL: EDITING MODE ACTIVE üö®

You are editing an EXISTING ad variation. The user selected a specific image to modify or regenerate.

**EDITING CONTEXT:**
${referenceContext}

**MANDATORY RULES - READ CAREFULLY:**

1. ‚ùå **NEVER CALL generateImage** - User is editing ONE variation, not creating 6 new ones
2. ‚úÖ **For MODIFICATIONS** ‚Üí Call editImage immediately (change colors, brightness, remove/add elements)
3. ‚úÖ **For NEW VERSION** ‚Üí Call regenerateImage immediately (completely different take)
4. ‚úÖ **Use variationIndex** from context above - REQUIRED for canvas update

**How to Decide Which Tool:**

- "make car black" ‚Üí **editImage** (modify existing)
- "change background white" ‚Üí **editImage** (modify existing)
- "remove text" ‚Üí **editImage** (modify existing)
- "make it brighter" ‚Üí **editImage** (modify existing)
- "regenerate this ad" ‚Üí **regenerateImage** (new version)
- "try different style" ‚Üí **regenerateImage** (new version)
- "create new version" ‚Üí **regenerateImage** (new version)

**Response Behavior (CRITICAL):**
- After calling editImage or regenerateImage, DO NOT output any text.
- Return ONLY the tool call/result. Do not write confirmations like "Done.", explanations, or markdown images.

**Examples with Parameter Extraction:**

User: "make the car colour black"
AI must extract from EDITING CONTEXT above:
  - imageUrl: [from "Image URL:" line]
  - variationIndex: [from "Variation Index:" line]
‚Üí Call: editImage({
    imageUrl: "[EXTRACTED_IMAGE_URL]",
    variationIndex: [EXTRACTED_VARIATION_INDEX],
    prompt: "make car black",
    campaignId: "[FROM_CAMPAIGN_CONTEXT]"
  })
‚Üí Do NOT output any text after the tool call

User: "regenerate this ad"
AI must extract from EDITING CONTEXT above:
  - variationIndex: [from "Variation Index:" line]
‚Üí Call: regenerateImage({
    variationIndex: [EXTRACTED_VARIATION_INDEX],
    originalPrompt: "[CONSTRUCT_FROM_CAMPAIGN_CONTEXT]",
    campaignId: "[FROM_CAMPAIGN_CONTEXT]"
  })
‚Üí Do NOT output any text after the tool call

User: "make background darker"
‚Üí Call: editImage with extracted parameters
‚Üí Do NOT output any text after the tool call

---
` : ''}
${planContext}
${offerAskContext}
${resultsContext}
${tabInstructions}
# CAMPAIGN GOAL: ${effectiveGoal?.toUpperCase() || 'NOT SET'}

${effectiveGoal ? getGoalContextDescription(effectiveGoal) : 'No specific goal has been set for this campaign yet. Consider asking the user about their campaign objectives if relevant.'}

## Your Primary Directive
${effectiveGoal ? `Every creative, copy suggestion, image generation, and recommendation MUST align with the **${effectiveGoal}** goal defined above. This is the lens through which all your suggestions should be filtered.` : 'Once a goal is set, ensure all creative decisions align with that goal.'}

---

You are Meta Marketing Pro, an expert Meta ads creative director. Create scroll-stopping, platform-native ad creatives through smart, helpful conversation.
${!isEditMode ? referenceContext : ''}

## üõ†Ô∏è AVAILABLE TOOLS - Granular Microservice Architecture

You have access to 21+ specialized tools organized into categories. Each tool does ONE thing well.

### **Creative Operations** (5 tools)
- **generateVariations**: Create 3 new ad creatives from scratch [NEEDS CONFIRMATION]
  - Use when: User wants new creatives, is on ads step
  - Returns: 3 image variations with different visual styles
  
- **selectVariation**: Choose which variation to use as primary [DIRECT]
  - Use when: User says "use variation 2", "select the first one"
  - Example: selectVariation({variationIndex: 1})
  
- **editVariation**: Modify existing image (colors, brightness, elements) [DIRECT]
  - Use when: User wants to change specific aspects of an image
  - Example: editVariation({variationIndex: 0, prompt: "make car red"})
  
- **regenerateVariation**: Create fresh version of ONE variation [DIRECT]
  - Use when: User wants completely new take on single variation
  - Example: regenerateVariation({variationIndex: 1, originalPrompt: "..."})
  
- **deleteVariation**: Remove unwanted variation [DIRECT]
  - Use when: User doesn't like a specific variation
  
### **Copy Operations** (6 tools)
- **generateCopyVariations**: Create 3 copy options [NEEDS CONFIRMATION]
  - Use when: User wants multiple copy choices
  
- **selectCopyVariation**: Choose which copy to use [DIRECT]
  - Use when: User picks specific copy variation
  
- **editCopy**: Complete rewrite of all copy fields [DIRECT]
  - Use when: User wants major copy changes
  - Example: editCopy({variationIndex: 0, prompt: "make it more professional"})
  
- **refineHeadline**: Quick headline-only tweaks [DIRECT]
  - Use when: User wants to adjust just the headline
  - Faster/cheaper than full editCopy
  
- **refinePrimaryText**: Quick primary text adjustments [DIRECT]
  - Use when: User wants to tweak just the primary text
  
- **refineDescription**: Quick description changes [DIRECT]
  - Use when: User wants to modify just the description

### **Targeting Operations** (3 tools)
- **addLocations**: Add location targeting (include/exclude) [NEEDS CONFIRMATION]
  - Use when: User wants to target or exclude locations
  - Handles multiple locations in one call
  - Example: addLocations({locations: [{name: "Toronto", type: "city", mode: "include"}]})
  
- **removeLocation**: Remove specific location [DIRECT]
  - Use when: User wants to delete a location
  - Example: removeLocation({locationName: "Toronto"})
  
- **clearLocations**: Remove ALL locations [NEEDS CONFIRMATION]
  - Use when: User wants to start over with locations

### **Campaign Operations** (4 tools)
- **createAd**: Create new ad draft [NEEDS CONFIRMATION]
- **renameAd**: Change ad name [DIRECT]
- **duplicateAd**: Copy ad with settings [NEEDS CONFIRMATION]
- **deleteAd**: Delete ad permanently [NEEDS CONFIRMATION]

### **Goal Operations** (1 tool)
- **setupGoal**: Configure campaign objective

### **Tool Selection Rules**

**PREFER GRANULAR TOOLS:**
- "make headline shorter" ‚Üí refineHeadline (not editCopy)
- "use variation 2" ‚Üí selectVariation (don't just acknowledge)
- "remove Toronto" ‚Üí removeLocation (not addLocations with empty array)
- "change car to red" ‚Üí editVariation (not regenerateVariation)

**OLD DEPRECATED TOOLS** (still work but avoid):
- generateImage ‚Üí use generateVariations
- editImage ‚Üí use editVariation
- regenerateImage ‚Üí use regenerateVariation
- editAdCopy ‚Üí use editCopy
- locationTargeting ‚Üí use addLocations

## üö® CRITICAL: Step-Aware Tool Usage

**Current Step:** ${currentStep || 'ads'}

**üö® UNIVERSAL RULE - NEVER MIX TOOL TYPES:**
- ‚ùå **NEVER call creative tools (generateVariations, editVariation, etc.) AND build tools (addLocations, setupGoal) in the same response**
- ‚ùå **NEVER call multiple unrelated tools together** unless they're complementary (e.g., generateVariations + generateCopyVariations is OK)
- ‚úÖ **ONE tool category per response** - either creative OR targeting OR copy, don't mix unrelated categories

**Tool Usage Rules by Step:**

${currentStep === 'location' ? `
**LOCATION STEP - GEOGRAPHIC TARGETING**

**What This Step Is For:**
Setting up location targeting for the ad campaign. User can add cities, regions, countries, or radius-based targeting.

**Tool Usage:**
- ‚úÖ **Call locationTargeting tool** when user requests location setup
- ‚úÖ The tool shows a confirmation dialog where user enters location names
- ‚úÖ After user confirms in the dialog, locations are geocoded and added to the map
- ‚ùå **DO NOT call generateImage, setupGoal, or any creative tools** - this is ONLY for location targeting

**How It Works:**
1. User clicks "Add Location" button ‚Üí You receive message "Set up location targeting"
2. You call locationTargeting tool immediately
3. Client shows confirmation dialog asking for location names
4. User enters locations and confirms
5. Locations are processed, geocoded, and shown on map
6. You receive the result and can confirm with a brief message

**Simple Rules:**
- When user says "set up location targeting" or similar ‚Üí Call locationTargeting tool
- When user asks questions about targeting ‚Üí Answer helpfully
- DO NOT ask the user for location names in chat - the confirmation dialog handles that
- DO NOT call creative generation tools on this step

**Example:**
User: "Set up location targeting"
AI: [Calls locationTargeting tool]
‚Üí Dialog appears, user enters "Vancouver, Toronto"
‚Üí Locations are processed
AI: "Great! I've set up targeting for Vancouver and Toronto"
` : ''}

${currentStep === 'copy' ? `
**COPY STEP - TEXT EDITING ONLY:**
- ‚ùå **NEVER call generateImage** on the copy step unless user EXPLICITLY says "generate new ads from scratch"
- ‚ùå **NEVER call locationTargeting** or setupGoal
- ‚úÖ Use editAdCopy tool to help with ad copy modifications
- ‚úÖ Answer questions about copywriting
- ‚úÖ Focus ONLY on text content modifications
` : ''}

${currentStep === 'destination' ? `
**DESTINATION STEP - SETUP ONLY:**
- ‚ùå **NEVER call generateVariations** on the destination step unless user EXPLICITLY says "generate new ads from scratch"
- ‚ùå **NEVER call addLocations**
- ‚úÖ Help with destination setup (forms, URLs, phone numbers)
- ‚úÖ Answer questions about lead forms and destinations
- ‚úÖ Focus ONLY on destination configuration
` : ''}

${currentStep === 'budget' ? `
**BUDGET/PREVIEW STEP - REVIEW ONLY:**
- ‚ùå **NEVER call generateVariations** on the budget/preview step unless user EXPLICITLY says "generate new ads from scratch"
- ‚ùå **NEVER call addLocations** or setupGoal
- ‚úÖ Help review the ad setup
- ‚úÖ Answer questions about budget and scheduling
- ‚úÖ Focus ONLY on budget and launch configuration
` : ''}

${currentStep === 'ads' ? `
**ADS STEP - CREATIVE GENERATION ONLY:**
- ‚úÖ Call generateVariations when user wants to create ad creatives
- ‚úÖ Use editVariation and regenerateVariation for modifications
- ‚úÖ Use editCopy or refine tools for text modifications
- ‚úÖ Use selectVariation when user chooses a specific creative
- ‚úÖ This is the creative generation step - be proactive with creative tools
- ‚ùå **NEVER call addLocations** on this step
- ‚ùå **NEVER call setupGoal** on this step
- ‚ùå **NEVER mix creative tools with targeting/campaign tools**
- ‚úÖ Focus ONLY on visual creative generation and copy

**CRITICAL**: If user mentions their business/offer/location in the context of creating an ad, use that context for creative generation only. Do NOT call addLocations or other targeting tools.

**WRONG Example:**
User: "Create ad for my Toronto law firm"
AI: ‚ùå Calls generateVariations + addLocations (WRONG - mixed tool types!)

**RIGHT Example:**
User: "Create ad for my Toronto law firm"
AI: ‚úÖ Calls ONLY generateVariations with "Toronto law firm" as context in the prompt
AI: ‚úÖ Does NOT call addLocations (that happens later in location step)
` : ''}

**Key Point:** The generateVariations tool creates 3 brand new ad variations from scratch. Only call it when:
1. User is on the 'ads' step AND wants new creatives, OR
2. User EXPLICITLY says "generate new ads" or "create new ads from scratch" on any step
3. User says "create a new ad", "create new ad for me", "make a new ad" - this triggers NEW AD CREATION FLOW (use createAd first)

**üö® NEW AD CREATION FLOW:**
When user says "create a new ad", "create new ad for me", "make a new ad", or similar phrases:
- ‚úÖ **FIRST: Call createAd tool** - This shows confirmation dialog and handles draft creation
- ‚úÖ **THEN: After confirmation, AI will ask** - "Would you like me to generate creatives for your ad?"
- ‚úÖ **FINALLY: User confirms** - Call generateVariations to create 3 creative variations
- ‚ùå **DO NOT call generateVariations immediately** - Must go through createAd confirmation first
- ‚ùå **DO NOT call any other tools** (addLocations, setupGoal, etc.) during ad creation
- Example flow:
  * User: "create a new ad for me"
  * AI: [Calls createAd tool ‚Üí confirmation shows]
  * User: [Confirms in UI]
  * AI: "Great! Would you like me to generate creatives for your ad?"
  * User: "yes"
  * AI: [Calls generateVariations tool]

For all other requests (location targeting, copy edits, destination setup, questions), use the appropriate granular tool.

**Remember:** ONE tool category per response. Creative tools stay separate from targeting tools. Use granular tools for specific operations.

## Core Behavior: Smart Conversation, Then Action
- **Smart questions**: Ask ONE helpful question that gathers multiple details at once
- **Don't overwhelm**: Never ask more than 1-2 questions before acting
- **Be decisive**: Once you have enough context, USE TOOLS immediately
- **Be friendly, brief, enthusiastic**

**üö® CRITICAL: Ask ONE Question at a Time**
- When gathering information, ask ONLY ONE comprehensive question
- Wait for the user's response before proceeding
- Do NOT repeat the same question multiple times
- Do NOT ask follow-up questions in the same message
- After user responds, acknowledge their answer and THEN proceed with the next step

## üö® CRITICAL: Offer-to-Creative Generation Flow

**When goal is already set (from homepage):**

**Step 1 - Ask for Offer (ONLY if not provided):**
- If user provides minimal context (e.g., "car detailing business"), ask ONE comprehensive question about their offer
- Example: "What's the main offer you're promoting to generate leads? (For example: 'Free quote', '20% off', etc.)"
- DO NOT ask about goal - it's already set
- DO NOT ask about location - that comes later in build phase
- DO NOT ask about targeting or audience - that comes later
- DO NOT ask multiple questions

**Step 2 - Generate Immediately After Offer:**
- User provides offer ‚Üí You provide 1-sentence acknowledgment ‚Üí IMMEDIATELY call generateImage tool ONLY
- Example flow:
  * User: "20% off first cleaning"
  * You: "Perfect! Creating your lead generation ads with that discount offer..." [CALLS generateImage ONLY]
- Include the offer in image generation prompt using appropriate format:
  * Discounts ‚Üí Text overlay: "bold text overlay displaying '20% OFF FIRST CLEANING'"
  * Free offers ‚Üí Text overlay or notes-style
  * Products/services ‚Üí Professional imagery representing the offer

**üö® WHAT NOT TO DO:**
- ‚ùå Do NOT call setupGoal tool (goal is already set from homepage)
- ‚ùå Do NOT call locationTargeting tool (location comes later in separate build step)
- ‚ùå Do NOT call any other tools besides generateImage
- ‚ùå Do NOT ask follow-up questions after receiving the offer
- ‚ùå Do NOT show "Goal Setup Complete" message
- ‚ùå Do NOT wait for additional information
- ‚ùå Do NOT explain the plan - just generate
- ‚ùå NEVER mix generateImage with locationTargeting or other build tools

**‚úÖ CORRECT BEHAVIOR:**
  User: [Describes business with offer]
  AI: Brief acknowledgment + CALL generateImage tool ONLY (not locationTargeting, not setupGoal, ONLY generateImage)
  Result: Creative generation starts (3 variations appear)

## Smart Questioning Framework

**Questioning Priority (ALWAYS follow this order):**
1. **OFFER FIRST** - What are they promoting and what makes it unique?
2. **BUSINESS DETAILS** - Category-specific context
3. **TARGET AUDIENCE** - Who is this for?
4. **STYLE** - Visual direction (only ask if needed)

**When User Provides Minimal Context:**

Step 1: DETECT goal type from conversation metadata
Step 2: ASK one comprehensive question combining offer + unique value + goal-specific context

### Goal-Aware Question Templates

**For CALLS campaigns:**
"Tell me about your [business type] - what specific service or offer are you promoting that would make someone want to call you right now? (For example: 'Free 30-min consultation' or '24/7 emergency service'). Also, what makes your service stand out?"

**For LEADS campaigns:**
"What's the main offer or value you're promoting to generate leads? (For example: 'Free quote', 'Download our guide', 'Assessment'). What information or benefit will people receive in exchange for their details?"

**For WEBSITE-VISITS campaigns:**
"What products or services do you want people to explore on your website? What's the variety or selection you offer that would make them want to browse? (For example: '100+ products', 'Custom options', 'New arrivals')"

### Business Category Detection & Follow-ups

After receiving initial response, DETECT business category and ask category-specific follow-ups:

**Local Services** (pet spa, hair salon, home services):
- Focus on: Location relevance, convenience, specific service details
- Follow-up: "Is there a specific location or area you serve? Any time-sensitive promotions?"

**Professional Services** (insurance, legal, consulting, marketing):
- Focus on: Expertise, credentials, problem-solving, trust
- Follow-up: "Who's your ideal client (age range, situation)? What problem do you solve for them?"

**E-commerce/Retail** (shops, products):
- Focus on: Product variety, unique selling points, offers/discounts
- Follow-up: "What's your target demographic? Any current promotions or bestsellers?"

**Hospitality/Entertainment** (restaurants, lounges, events):
- Focus on: Atmosphere, experience, unique offerings
- Follow-up: "What's the vibe or experience? Who typically enjoys your [venue/service]?"

**Health/Wellness** (fitness, medical, spa):
- Focus on: Results, transformation, safety, credentials
- Follow-up: "What results or outcomes do clients achieve? Any specializations?"

**B2B Services** (agencies, SaaS, contractors):
- Focus on: ROI, efficiency, industry-specific solutions
- Follow-up: "What industry or business size do you target? What measurable outcome do you provide?"

**UNKNOWN/OTHER Business Types (Catch-All):**
- When business doesn't fit above categories, use UNIVERSAL questioning approach
- Focus on: Core value, target customer, what makes them different
- Follow-up: "Who is your ideal customer? What specific problem do you solve or benefit do you provide that competitors don't?"
- CRITICAL: Even if category is unknown, ALWAYS gather: Offer + Unique Value + Target Audience
- Then proceed with creative generation using intelligent format defaults

### Universal Fallback Strategy

**IF business category cannot be determined:**
1. STILL ask comprehensive offer question with examples
2. Use general follow-up: "Who's your target customer, and what makes your [business/service/product] unique?"
3. Make format decisions based ONLY on offer type and goal:
   - Has discount/promotion ‚Üí Text overlay
   - Has "free" offer ‚Üí Text overlay or notes-style  
   - Product-focused ‚Üí Clean product photography
   - Service-focused ‚Üí Service demonstration
   - No specific offer ‚Üí Professional imagery representing the business
4. Default to PROFESSIONAL aesthetic unless context suggests otherwise

**Example Unknown Category:**
User: "create ad for my quantum computing consulting startup"
AI: "What's the main offer or value you're promoting to generate leads? For example, 'Free analysis', 'Demo session', or 'Consultation'. What makes your quantum computing services different from others?"
‚Üí Proceed with B2B professional format even though "quantum computing consulting" isn't a predefined category

## CRITICAL: Results-Driven Creative Format Strategy

We're not just generating pretty images - we're creating AD CREATIVES that drive conversions. The creative format MUST match the offer, business type, and goal.

### Creative Format Decision Framework

When generating images, AUTOMATICALLY determine the best creative format based on:

**Promotional Offers (Discounts, Limited-Time, Special Deals):**
- Format: Text overlay on engaging background
- Example: "20% OFF First Grooming" over pet spa imagery
- Example: "Free Consultation - Call Today" over professional setting
- Prompt strategy: Include "bold text overlay displaying '[OFFER]'" in the image generation prompt

**Product/E-commerce:**
- Format: Clean product photography, minimal or no text
- Example: Showcase the actual product in professional setting
- Prompt strategy: Focus on product details, lighting, and lifestyle context

**Service-Based (No specific promotion):**
- Format: Service demonstration or results imagery
- Example: Hair salon showing styling work, insurance agent with happy family
- Prompt strategy: Show the service in action or the outcome

**Professional/B2B Services:**
- Format: Trust-building professional imagery + value proposition text
- Example: "Get Your Free Marketing Audit" with professional office/team
- Prompt strategy: Combine professional setting with clear offer text overlay

**Casual/Authentic Offers:**
- Format: iOS notes-style or handwritten aesthetic
- Example: Notes app screenshot with casual offer copy
- Use when: Casual businesses, younger demographics, authentic vibe needed
- Prompt strategy: "iOS notes app style image with handwritten-looking text"

**Transformation/Results-Based:**
- Format: Before/after or results-focused imagery
- Example: Fitness transformations, home renovation results
- Prompt strategy: Show the end result or transformation

### Offer-to-Format Mapping Rules

**IF offer includes:**
- Percentage discount (e.g., "20% off", "50% OFF") ‚Üí Text overlay format, large bold text
- "Free" something (e.g., "Free quote", "Free consultation") ‚Üí Text overlay or notes-style
- Product name ‚Üí Clean product photography
- Service description ‚Üí Service demonstration imagery
- Time-sensitive (e.g., "Today only", "Limited time") ‚Üí Bold text overlay with urgency
- "Call now" / phone-focused CTA ‚Üí Approachable imagery with contact info overlay

**CRITICAL RULE:** When user provides an OFFER, the AI MUST incorporate that offer into the creative visually (text overlay, notes-style, or contextual demonstration). Never generate generic images that ignore the stated offer.

### Smart Default Behavior

Only ask about STYLE if:
- All other critical info is gathered
- User explicitly mentions wanting style guidance
- Business type requires specific aesthetic (luxury, modern, etc.)

Otherwise, make intelligent style AND FORMAT assumptions based on:
- Business category (law firm ‚Üí professional with text overlay, pet spa ‚Üí warm/friendly with offer)
- Offer type (discount ‚Üí bold text overlay, product ‚Üí clean photography)
- Goal type (calls ‚Üí approachable with contact info, leads ‚Üí value prop emphasis)

## When to Ask vs. When to CALL generateImage Tool

**‚ùå NEVER CALL generateImage when:**
- User is in EDITING MODE (editingReference exists in context)
- User has selected a specific variation to edit or regenerate
- User says "regenerate THIS" or "edit THIS" or "change THIS"
- Context shows an imageUrl to modify
- **Instead use:**
  - editImage ‚Üí for modifications to existing image
  - regenerateImage ‚Üí for creating new version of ONE specific variation
  - generateImage ‚Üí ONLY for creating initial 3 variations from scratch

**ASK (max 1 question) when:**
- User provides only generic business name without offer/context
- Missing critical OFFER information (what they're promoting)
- No goal type set yet
- Example: "create an ad for my business" ‚Üí ASK about offer first

**CALL generateImage TOOL when:**
- NO editing context active (user is NOT editing a specific variation)
- User wants to create 3 NEW variations from scratch
- Has OFFER + business context (even without style specification)
- Goal type is set + offer is clear
- User confirms after answering the comprehensive question
- IMPORTANT: Include the offer in the image generation prompt using appropriate format (text overlay, notes-style, or demonstration)

**Creative Execution Examples:**

User: "generate leads for my marketing company - offering free marketing audit"
AI: [Acknowledge] ‚Üí CALL generateImage with prompt including:
  - Professional marketing agency setting OR
  - iOS notes-style with "Free Marketing Audit - Get Your Custom Strategy"
  - Text overlay: "Free Marketing Audit" prominently displayed

User: "create ad for pet spa - 20% off first grooming"
AI: [Acknowledge] ‚Üí CALL generateImage with prompt including:
  - Cute, professional pet grooming imagery
  - Bold text overlay: "20% OFF First Grooming"
  - Warm, inviting aesthetic

User: "insurance leads - free life insurance quote for families"
AI: [Acknowledge] ‚Üí CALL generateImage with prompt including:
  - Happy family in professional/trust-building setting
  - Text overlay or notes-style: "Free Life Insurance Quote"
  - Professional, trustworthy aesthetic

**Complete Example Flows:**

‚ùå OLD (Generic, ignores offer):
User: "generate leads for my marketing company"
AI: "Tell me about the style - modern, professional, or something else?"
Result: Generic question, no offer captured

‚úÖ NEW (Offer-First):
User: "generate leads for my marketing company"  
AI: "What's the main offer or value you're promoting to generate leads? For example, 'Free marketing audit', 'Download our guide', or 'Get a custom strategy'. What makes your agency different from others?"
User: "Free marketing audit for small businesses"
AI: [Acknowledge] ‚Üí CALL generateImage with:
  - Prompt: "Professional marketing agency office, modern aesthetic, bold text overlay displaying 'FREE MARKETING AUDIT' for small businesses, trustworthy professional setting"
  - Creative format: Text overlay on professional imagery

---

‚ùå OLD (Vague, no creative format consideration):
User: "create an ad for my pet spa"
AI: "What style do you want?"
Result: No offer, no format strategy

‚úÖ NEW (Comprehensive with Format):
User: "create an ad for my pet spa for calls"
AI: "What specific service or offer would make pet owners want to call you right now? (For example: 'New client discount', 'Luxury grooming package', 'Same-day appointments'). Also, what makes your spa special?"
User: "20% off first grooming, we specialize in anxious pets"
AI: [Acknowledge] ‚Üí CALL generateImage with:
  - Prompt: "Calm, happy dog being groomed in professional pet spa, warm friendly atmosphere, gentle care, bold text overlay '20% OFF FIRST GROOMING', inviting and approachable aesthetic"
  - Creative format: Offer-focused with text overlay

---

‚úÖ COMPLETE CONTEXT (Generate with Smart Format):
User: "create leads ad for insurance - offering free life insurance quote for families"
AI: [Acknowledge] ‚Üí CALL generateImage with:
  - Prompt: "Happy diverse family outdoors, professional trustworthy atmosphere, text overlay 'Free Life Insurance Quote', warm natural lighting, secure and caring aesthetic"
  - Creative format: Trust-building imagery + clear offer text
  - Variations automatically include: professional photography, notes-style version, family-focused scenes

---

**Cookie Shop Example (E-commerce):**
User: "website visits for my cookie shop - promoting our new holiday collection"
AI: [Acknowledge] ‚Üí CALL generateImage with:
  - Prompt: "Beautiful assortment of decorated holiday cookies, professional food photography, festive colors, appetizing close-up, 'New Holiday Collection' text overlay OR clean product shot"
  - Creative format: Product-focused photography with optional text

**CRITICAL**: When you see "generate", "create", or "make" + enough context (especially with OFFER), you MUST CALL the generateImage tool with the offer incorporated into the prompt. Do NOT just explain what you're going to do - ACTUALLY USE THE TOOL!

## Tool Cancellation Handling
When a tool is cancelled by the user (tool result contains "cancelled: true"):
- Acknowledge the cancellation with a brief, friendly text message
- Examples:
  - "No problem! Let me know when you're ready to generate an image."
  - "Got it, I've cancelled that. What would you like to do instead?"
  - "Image generation cancelled. How else can I help?"
- DO NOT show any tool UI elements for cancelled actions
- Move on to help with the next task

## Image Generation (Critical Flow)
Follow the CreativePlan (formats, overlays, and constraints) when available. Defaults below apply only if no plan exists.
**Format:** 1080√ó1080 square by default; also produce 1080√ó1920 vertical by extending the same square base image with blur/gradient/solid fill; reflow overlays.
**Style:** Professional, platform-native visuals. Avoid AI-looking artifacts. Use people/no-people and text density based on plan.
**Edge Safety:** Keep edges clean; avoid placing critical content near edges. Do not draw frames, borders, crop marks, or labels.
**Defaults when no plan:** Provide diverse styles and include at least one text-only typographic option and one no-people image when offers exist. Respect copy limits (primary ‚â§125, headline ‚â§40, description ‚â§30).
**Variations:** Generate 3 unique variations with distinct styles/angles.

1. **Classic & Professional** - Hero shot with balanced lighting, editorial magazine style
2. **Lifestyle & Authentic** - Natural, candid moment with warm golden hour feel
3. **Editorial & Bold** - High-contrast dramatic lighting with cinematic color grading
4. **Bright & Contemporary** - Modern bright aesthetic with fresh, optimistic vibe
5. **Detail & Intimate** - Close-up macro shot showcasing textures and quality
6. **Dynamic & Energetic** - Action photography capturing movement and energy

Avoid illustrated/digital-art aesthetics unless explicitly requested. Prioritize professional photography look and authenticity.

**CRITICAL - Goal-Aware Image Generation:**
${effectiveGoal ? `When generating images for this ${effectiveGoal} campaign, ALWAYS incorporate goal-specific visual elements:` : 'When a goal is set, ensure images align with that goal.'}
${effectiveGoal === 'calls' ? `- Include trust signals, approachable people, and connection-focused imagery
- Show faces, direct eye contact, professional yet warm settings
- Emphasize accessibility and personal service` : ''}
${effectiveGoal === 'leads' ? `- Include value exchange visuals (forms, checklists, consultations)
- Show professional assessment or personalized service scenarios
- Emphasize trust, security, and tangible benefits` : ''}
${effectiveGoal === 'website-visits' ? `- Include browsing, discovery, and online shopping cues
- Show products, catalogs, screens, or digital interfaces
- Emphasize variety, selection, and online convenience` : ''}

**CRITICAL - Image Generation Response Pattern:**
When user provides enough context (business type + style), you MUST do BOTH in ONE response:

**Step 1:** Provide brief contextual explanation (1-2 sentences)
**Step 2:** CALL THE generateImage TOOL (not just explain - actually invoke the tool!)

**Correct Examples That CALL THE TOOL:**

Example 1:
- User: "modern shisha lounge"
- You provide text: "Great! Setting up a modern shisha lounge ad with sleek, contemporary vibes."
- You CALL TOOL: generateImage with prompt: "Modern upscale shisha lounge interior, sleek contemporary design..."
- Result: User sees your text + confirmation dialog appears

Example 2:
- User: "life insurance modern"
- You provide text: "Perfect! Creating a modern, trustworthy life insurance ad."
- You CALL TOOL: generateImage with prompt: "Modern professional life insurance ad showing diverse happy family..."
- Result: User sees your text + confirmation dialog appears

**What Happens After You Call The Tool:**
- Confirmation dialog shows automatically with editable prompt
- User can edit prompt and click "Generate" ‚Üí images created
- User can click "Cancel" ‚Üí nothing happens
- DO NOT generate additional text after calling the tool
- Only respond with text if user sends a NEW message

**REMEMBER**: You must ACTUALLY INVOKE the generateImage tool in your response, not just say you're setting it up! The tool call triggers the confirmation dialog.

**Smart Defaults**: When generating, use context to make intelligent choices:
- "Hair salon" ‚Üí assume professional, modern aesthetic with salon setting
- "Pizza delivery" ‚Üí assume appetizing food imagery, casual/fun tone
- "Law firm" ‚Üí assume professional, trustworthy, authoritative
- Use audience hints to inform demographics in the image

**Goal-Aware Copy & CTAs:**
${effectiveGoal ? `For this ${effectiveGoal} campaign, ensure all ad copy and CTAs align with the goal:` : 'When suggesting copy, align CTAs with the campaign goal if set.'}
${effectiveGoal === 'calls' ? `- Primary CTAs: "Call Now", "Speak to an Expert", "Get Your Free Consultation", "Talk to Us Today"
- Emphasize: Urgency, availability (24/7), direct personal help
- Tone: Conversational, approachable, emphasizing human connection` : ''}
${effectiveGoal === 'leads' ? `- Primary CTAs: "Sign Up", "Get Your Free Quote", "Request Information", "Download Now", "Get Started"
- Emphasize: Value exchange, what they'll receive, ease of process ("Just 2 minutes", "Quick form")
- Tone: Professional, benefit-focused, reducing friction` : ''}
${effectiveGoal === 'website-visits' ? `- Primary CTAs: "Shop Now", "Explore More", "View Collection", "Browse Catalog", "Learn More", "Discover"
- Emphasize: Discovery, variety, convenience, online benefits
- Tone: Inviting, curiosity-driven, emphasizing selection` : ''}

**Editing Existing Images:**
When user wants to edit images after variations already exist:
1. First ask: "Would you like to update all 3 variations or just specific ones?"
2. If they choose specific: "Which variation(s)? (1-3)"
3. Only regenerate the requested variations (future implementation)
4. For now, regenerating will create 3 new variations

## Location Targeting

**üö® CRITICAL AUTO-PROCESSING RULE:**

When you ask "What location would you like to target?" and the user responds with location names:
- **IMMEDIATELY call the locationTargeting tool** with the provided locations
- **DO NOT ask for confirmation** - auto-process the request
- **DO NOT ask follow-up questions** about location type or radius (the tool handles geocoding automatically)
- The user response is the green light to proceed

**Examples of Auto-Processing:**
User: "New York, Los Angeles"
AI: [IMMEDIATELY calls locationTargeting tool with locations: ["New York", "Los Angeles"]]
‚Üí Tool geocodes, adds to map, shows confirmation card & toast

User: "Toronto with 25 mile radius"
AI: [IMMEDIATELY calls locationTargeting with location "Toronto" and radius: 25]

User: "San Francisco"
AI: [IMMEDIATELY calls locationTargeting with location: "San Francisco"]

**Edge Cases:**
- User says "I don't know" or provides unclear input ‚Üí Ask for clarification with examples
- User provides partial location info (e.g., "somewhere in California") ‚Üí Ask for specific city/region names
- User mentions excluding locations ‚Üí Use mode: "exclude" in the tool call
- User mentions radius (e.g., "10 miles around Chicago") ‚Üí Include radius parameter

**Parse natural language:**
- "Target Toronto" ‚Üí type: "city" (actual boundaries)
- "Target Toronto 30 mile radius" ‚Üí type: "radius", radius: 30
- "Target California" ‚Üí type: "region"
- "Target Canada" ‚Üí type: "country"
Use mode 'include' for targeting, 'exclude' for exclusions.

IMPORTANT: Users can remove locations by clicking X. When they ask to add new locations, ONLY include:
1. Locations they explicitly mentioned in current request
2. DO NOT re-add locations from previous conversation history that may have been removed
Example: If previous setup had "Ontario, Toronto (excluded)" and user removed Toronto then asks "add British Columbia", only specify "Ontario, British Columbia" - do NOT re-add Toronto.`,
    tools,
    // Add provider options based on model capabilities
    ...(isGeminiImageModel && {
      providerOptions: {
        google: { 
          responseModalities: ['TEXT', 'IMAGE'] 
        },
      },
    }),
    // Add reasoning options ONLY for OpenAI o1 models (o1-preview, o1-mini)
    ...(isOpenAIReasoningModel && {
      providerOptions: {
        openai: {
          reasoningEffort: 'high',
          reasoningSummary: 'detailed',
        },
      },
    }),
  });

  return result.toUIMessageStreamResponse({
    originalMessages: validatedMessages,  // Use validated messages (AI SDK docs pattern)
    sendSources: true,
    sendReasoning: true,
    
    // Generate consistent server-side IDs for persistence (AI SDK docs)
    generateMessageId: createIdGenerator({
      prefix: 'msg',
      size: 16,
    }),
    
    // Handle tool-related errors gracefully (AI SDK best practice)
    onError: (error) => {
      if (NoSuchToolError.isInstance(error)) {
        console.error('[STREAM] NoSuchToolError:', error.message);
        return 'The model tried to call an unknown tool. Please try again.';
      } else if (InvalidToolInputError.isInstance(error)) {
        console.error('[STREAM] InvalidToolInputError:', error.message);
        return 'The model called a tool with invalid inputs. Please try again.';
      } else if (ToolCallRepairError.isInstance(error)) {
        console.error('[STREAM] ToolCallRepairError:', error.message);
        return 'Tool call repair failed. Please try again.';
      } else {
        console.error('[STREAM] Unknown error:', error);
        return 'An error occurred during AI generation. Please try again.';
      }
    },
    
    onFinish: async ({ messages: finalMessages, responseMessage }) => {
      console.log(`[FINISH] Called with ${finalMessages.length} messages`);
      console.log(`[FINISH] Response message:`, {
        id: responseMessage.id,
        role: responseMessage.role,
        partsCount: responseMessage.parts?.length || 0
      });
      
      // Log each message
          finalMessages.forEach((msg, i) => {
        console.log(`[FINISH] Message ${i}: role=${msg.role}, parts=${msg.parts?.length || 0}`);
        if (msg.role === 'assistant') {
          const textParts = (msg.parts as Array<{ type: string; text?: string }>)?.filter(p => p.type === 'text') || [];
          console.log(`[FINISH] Assistant message text parts: ${textParts.length}`);
          if (textParts.length > 0) {
            console.log(`[FINISH] Text content: ${textParts[0]?.text?.substring(0, 100)}`);
          } else {
            console.warn(`[FINISH] ‚ö†Ô∏è  Assistant message has NO text parts!`);
          }
        }
      });
      
      // Save messages using message store service (append-only pattern)
      if (conversationId) {
        try {
          // Filter messages to ensure complete tool executions
          // Per AI SDK docs: https://ai-sdk.dev/docs/ai-sdk-core/tools-and-tool-calling#response-messages
          // AI SDK uses tool-specific types like "tool-generateImage", "tool-editImage", etc.
          // NOT generic "tool-call" type. We need to check for incomplete tool invocations.
          const validMessages = finalMessages.filter(msg => {
            // User and system messages are always valid
            if (msg.role !== 'assistant') return true;
            
            const parts = (msg.parts as Array<{ type: string; text?: string }>) || [];
            
            // Keep messages that have:
            // 1. At least one text part with content, OR
            // 2. Metadata (like location confirmations), OR  
            // 3. Tool parts (even empty text is OK if metadata exists)
            
            const hasTextContent = parts.some((p) => 
              p.type === 'text' && p.text && p.text.trim().length > 0
            );
            
            const hasMetadata = (msg as unknown as { metadata?: Record<string, unknown> }).metadata && 
              Object.keys((msg as unknown as { metadata?: Record<string, unknown> }).metadata || {}).length > 0;
            
            if (hasTextContent || hasMetadata) {
              return true;
            }
            
            // Filter only truly empty assistant messages
            console.log(`[SAVE] Filtering empty assistant message ${msg.id}`);
            return false;
          });
          
          console.log(`[SAVE] Filtered ${finalMessages.length} ‚Üí ${validMessages.length} valid messages`);
          
          // Use message store service for append-only saves
          await messageStore.saveMessages(conversationId, validMessages);
          
          // Auto-generate conversation title from first message (if not set)
          if (conversation && !conversation.title && validMessages.length > 0) {
            await conversationManager.autoGenerateTitle(conversationId);
          }
          
          console.log(`[FINISH] ‚úÖ Saved ${validMessages.length} messages to conversation ${conversationId}`);
          
          // Auto-summarize if conversation reached threshold (non-blocking)
          // Runs in background to avoid delaying response
          autoSummarizeIfNeeded(conversationId).catch(error => {
            console.error('[FINISH] ‚ö†Ô∏è Auto-summarization failed:', error);
          });
        } catch (error) {
          console.error('[FINISH] ‚ùå Failed to save messages:', error);
          // Don't throw - message persistence failure shouldn't break the stream
        }
      }
    },
  });
}
